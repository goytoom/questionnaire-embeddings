{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0887e99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "# formatting\n",
    "import re\n",
    "def add_comma(match):\n",
    "    return match.group(0) + ','\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"An input array is constant; the correlation coefficient is not defined.\")\n",
    "\n",
    "# determine accuracy rates of human judges\n",
    "def topRaters(targets_data, human_data, df_folds):\n",
    "    human_data = raters_data.copy()\n",
    "    targets_h = []\n",
    "    for target in targets_data.target_nr: #iterate over targets\n",
    "        for fold in range(10): #iterate over folds\n",
    "            test_items_idx = df_folds.loc[df_folds.fold_nr==fold+1, \"test_items\"].iloc[0]\n",
    "            test_items_names = [\"q\" + str(x) for x in test_items_idx]\n",
    "            true_x  = targets_data.loc[targets_data.target_nr == target, test_items_names].iloc[0]\n",
    "            if any((human_data.target == target) & (human_data.fold == fold+1)):\n",
    "                human_x = human_data.loc[(human_data.target == target) & (human_data.fold == fold+1), test_items_names].iloc[0]\n",
    "                human_id = human_data.loc[(human_data.target == target) & (human_data.fold == fold+1), \"id\"].iloc[0]\n",
    "                nas = np.logical_or(np.isnan(true_x), np.isnan(human_x))   # in case nan are in vector\n",
    "                corr_human, p_human = pearsonr(true_x[~nas], human_x[~nas])\n",
    "                targets_h.append([corr_human, human_id])\n",
    "            else:\n",
    "                corr_human, p_human = [np.nan, np.nan]\n",
    "                targets_h.append([corr_human, np.nan])\n",
    "        targets_df = pd.DataFrame(targets_h, columns=[\"accuracy\", \"id\"])\n",
    "\n",
    "    return targets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e4deb3",
   "metadata": {},
   "source": [
    "## Choose questionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "946724fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = \"riasec\" #BIG5, 16PF, RIASEC, HSQ\n",
    "h_path = \"../human_studies/\" + d.upper() + \"/\" + d.lower() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1860b46",
   "metadata": {},
   "source": [
    "### Import & Process Human Response Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "215c8be8-fe71-42e0-8990-8b14ff5a7ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load human judges responses\n",
    "raters_data = pd.read_csv(h_path + \"_qualtrics_cleaned.csv\", index_col = 0)\n",
    "\n",
    "# load target responses (original data)\n",
    "targets_data = pd.read_csv(h_path + \"_targets_data.csv\", index_col=0)\n",
    "# rename questions by order (e.g., \"q1\")\n",
    "new_cols_names = [\"q\" + str(x) for x in range(1, len(targets_data.columns[4:])+1)] \n",
    "rename_cols_dict = {k:v for k,v in zip(targets_data.columns[4:].tolist(), new_cols_names)}\n",
    "targets_data.rename(columns=rename_cols_dict, inplace=True) \n",
    "\n",
    "# load auxiliary data\n",
    "df_folds = pd.read_csv(h_path + \"_question_folds.csv\") # save to files\n",
    "df_folds.test_items = df_folds.test_items.apply(lambda x: re.sub(r'\\[[0-9\\.\\s]+\\]', add_comma, x)).apply(lambda x: re.sub(r'([0-9\\.]+)', add_comma, x)).apply(lambda x: np.array(eval(x)[0]))\n",
    "df_folds.train_items = df_folds.train_items.apply(lambda x: re.sub(r'\\[[0-9\\.\\s]+\\]', add_comma, x)).apply(lambda x: re.sub(r'([0-9\\.]+)', add_comma, x)).apply(lambda x: np.array(eval(x)[0]))\n",
    "\n",
    "# determine top raters\n",
    "df = topRaters(targets_data, raters_data, df_folds)\n",
    "top_raters = df.sort_values(\"accuracy\", ascending=False)[:60].id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77ed977d-2004-444f-a7ee-e95996d6861e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save top_raters list as text file\n",
    "with open(h_path + \"_top_raters.txt\", \"w\") as f:\n",
    "    for line in top_raters:\n",
    "        f.write(f\"{line}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
